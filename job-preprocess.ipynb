{"cells":[{"cell_type":"code","source":["from pyspark.ml.functions import vector_to_array as toArray\nfrom pyspark.ml.feature   import VectorAssembler\nfrom pyspark.ml.feature   import StringIndexer\nfrom pyspark.ml.feature   import OneHotEncoder\nfrom pyspark.ml.feature   import RobustScaler\nfrom pyspark.ml.feature   import Bucketizer\nfrom pyspark.ml.feature   import Imputer\n\nfrom pyspark.sql          import functions as F\nfrom pyspark.sql          import Window as W\nfrom pyspark.sql          import types as T"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"e9e097a0-23b6-4bad-9a6e-072b49d1022a","inputWidgets":{},"title":"Environment"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["recipe    = \"recipe-A\"; projectPath = \"/mnt/data-dev/project-adult-income/\"\ndsPath    = projectPath + \"dataset.csv\";\ntargetCol = \"class\"; naTokens = [\"?\"]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"e33c8773-ef33-4a86-94b6-0b52b76c6b66","inputWidgets":{},"title":"Job parameters"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["df = spark.read.option(\"inferSchema\", True).option(\"header\", True).csv(dsPath)\n\nfeatureCols = [(col[0], col[1]) for col in df.dtypes if col[0] != targetCol]\nfeatureCols = [F.col(col[0]).alias(f\"x{idx}NUM\") if col[1] != \"string\" \n               else F.col(col[0]).alias(f\"x{idx}CAT\") for idx, col \n               in enumerate(featureCols)]\n\ndf = df.select(F.col(targetCol).alias(\"y\"), *featureCols)\nnumCols = [col for col in df.columns if \"NUM\" in col]\ncatCols = [col for col in df.columns if \"CAT\" in col]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"c98b3069-8854-44dc-92a9-474cb7004fa4","inputWidgets":{},"title":"Load and categorize cols"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["for col in catCols + [\"y\"]: df = df.withColumn(col, F.trim(F.col(col)))\n\nfor col in df.columns:\n    if len(naTokens) != 0:\n        expr = F.when(F.col(col).isin(naTokens), F.lit(None))\n        expr = expr.otherwise(F.col(col))\n        df   = df.withColumn(col, expr)\n\nfor col in catCols + [\"y\"]:\n    expr     = F.when(F.col(col).isNull(), F.lit(None)).otherwise(F.col(f\"{col}x\"))\n    indexer  = StringIndexer().setInputCol(col).setOutputCol(f\"{col}x\")\n    df       = indexer.setHandleInvalid(\"keep\").fit(df).transform(df)\n    df       = df.withColumn(f\"{col}x\", F.col(f\"{col}x\").cast(\"int\"))\n    df       = df.withColumn(f\"{col}x\", expr).drop(col)\n    df       = df.withColumnRenamed(f\"{col}x\", col)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"b387b496-2eac-422d-8883-6b44c2a72d54","inputWidgets":{},"title":"Clean and format"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["numClass    = df.select(\"y\").dropDuplicates().count();  validProp = 0.2\nvalid       = df.sampleBy(\"y\", {c: validProp for c in range(numClass)})\ntrain       = df.subtract(valid).cache(); train.count()\nvalid       = valid.cache(); valid.count()\n\ninputCols   = numCols\noutputCols  = [f\"{col}x\" for col in inputCols]\noutterCols  = [col for col in df.columns if col not in inputCols]\ncolNameMap  = [F.col(c1).alias(c2) for c1, c2 in zip(outputCols, inputCols)]\nimputer     = Imputer().setInputCols(inputCols).setOutputCols(outputCols)\nimputer     = imputer.setStrategy(\"median\").fit(train)\ntrain       = imputer.transform(train).select(*outterCols, *colNameMap)\nvalid       = imputer.transform(valid).select(*outterCols, *colNameMap)\n\ninputCols   = catCols\noutputCols  = [f\"{col}x\" for col in inputCols]\noutterCols  = [col for col in df.columns if col not in inputCols]\ncolNameMap  = [F.col(c1).alias(c2) for c1, c2 in zip(outputCols, inputCols)]\nimputer     = Imputer().setInputCols(inputCols).setOutputCols(outputCols)\nimputer     = imputer.setStrategy(\"mode\").fit(train)\ntrain       = imputer.transform(train).select(*outterCols, *colNameMap)\nvalid       = imputer.transform(valid).select(*outterCols, *colNameMap)\n\ninputCols   = catCols\noutputCols  = [f\"{col}x\" for col in inputCols]\noutterCols  = [col for col in df.columns if col not in inputCols]\ncolNameMap  = [F.col(c1).alias(c2) for c1, c2 in zip(outputCols, inputCols)]\nencoder     = OneHotEncoder().setInputCols(inputCols).setOutputCols(outputCols)\nencoder     = encoder.setHandleInvalid(\"keep\").fit(train)\ntrain       = encoder.transform(train).select(*outterCols, *colNameMap)\nfor col in inputCols: train = train.withColumn(col, toArray(col))\ntrain       = train.withColumn(\"catFeatures\", F.concat(*inputCols))\ntrain       = train.drop(*inputCols)\nvalid       = encoder.transform(valid).select(*outterCols, *colNameMap)\nfor col in inputCols: valid = valid.withColumn(col, toArray(col))\nvalid       = valid.withColumn(\"catFeatures\", F.concat(*inputCols))\nvalid       = valid.drop(*inputCols)\n\ninputCols   = numCols\nassembler   = VectorAssembler().setInputCols(inputCols).setOutputCol(\"numFeatures\")\ntrain       = assembler.transform(train).drop(*inputCols)\nvalid       = assembler.transform(valid).drop(*inputCols)\n\ninputCol    = \"numFeatures\"\nscaler      = RobustScaler(withCentering=True).setInputCol(inputCol)\nscaler      = scaler.setOutputCol(f\"{inputCol}x\").fit(train)\ntrain       = scaler.transform(train).drop(inputCol)\ntrain       = train.withColumnRenamed(f\"{inputCol}x\", inputCol)\ntrain       = train.withColumn(inputCol, toArray(inputCol))\nvalid       = scaler.transform(valid).drop(inputCol)\nvalid       = valid.withColumnRenamed(f\"{inputCol}x\", inputCol)\nvalid       = valid.withColumn(inputCol, toArray(inputCol))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"4b998367-d760-414f-a465-60a58bb24815","inputWidgets":{},"title":"Preprocess and split"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["dataset     = train  .withColumn(\"valid\", F.lit(0)).union(valid.withColumn(\"valid\", F.lit(1)))\ndataset     = dataset.withColumn(\"x\", F.concat(\"numFeatures\", \"catFeatures\"))\ndataset     = dataset.withColumn(\"x\", F.col(\"x\").cast(T.ArrayType(T.DecimalType(19, 4))))\ndataset     = dataset.withColumn(\"x\", F.col(\"x\").cast(T.ArrayType(T.FloatType())))\n\ndataset.drop(\"numFeatures\", \"catFeatures\").coalesce(1).write.mode(\"overwrite\") \\\n.parquet(projectPath + recipe + \"/train/dataset\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"3a6f6edc-e5b2-4b15-a5d2-56e576462860","inputWidgets":{},"title":"Write"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"job-preprocess","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":202862372226945}},"nbformat":4,"nbformat_minor":0}
